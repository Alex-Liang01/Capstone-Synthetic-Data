{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cramer's V\n",
    "def cramers_v(df):\n",
    "    confusion_matrix = pd.crosstab(df['countryCode'],df['Language'])  \n",
    "    chi2, p, dof, expected= chi2_contingency(confusion_matrix)  \n",
    "    n = confusion_matrix.sum().sum()\n",
    "    k = min(confusion_matrix.shape)  \n",
    "    if k > 1:\n",
    "        return np.sqrt(chi2 / (n * (k - 1)))\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Function to perform Chi-Square test and calculate Cramer's V for all pairs of categorical variables\n",
    "def chi_square_test(df, cat_vars):\n",
    "    results = {}\n",
    "    for var1 in cat_vars:\n",
    "        for var2 in cat_vars:\n",
    "            if var1 != var2:\n",
    "                try:\n",
    "                    # Calculate Chi-Square and Cramer's V\n",
    "                    chi2, p, dof, ex = chi2_contingency(pd.crosstab(df[var1], df[var2]))\n",
    "                    cramer_v = cramers_v(df)\n",
    "                    results[(var1, var2)] = (chi2, p, cramer_v)\n",
    "                except ValueError:\n",
    "                    # Skip invalid pairs (e.g., if one variable has only one unique value)\n",
    "                    results[(var1, var2)] = (np.nan, np.nan, np.nan)\n",
    "    return results\n",
    "\n",
    "\n",
    "# Randomly filling in data of defined columns with other values in columns based off dependency\n",
    "def random_fill(df,dependency,percentage):\n",
    "    df = df.copy()\n",
    "\n",
    "    columns=['Language','gender','generation','pilStatus']\n",
    "\n",
    "    for col in columns:\n",
    "            num_rows = len(df)\n",
    "            num_to_replace = int((percentage / 100) * num_rows)  \n",
    "            random_indices = np.random.choice(df.index, num_to_replace, replace=False)  \n",
    "            \n",
    "            random_values = np.random.choice(df[col], num_to_replace, replace=True)\n",
    "            df.loc[random_indices, col] = random_values\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generating(player, obs, missing_percentages, missing_cols,name,path):\n",
    "    for row in obs:\n",
    "        for percentage in missing_percentages:\n",
    "            # Sampling obs number of rows\n",
    "            data = player.sample(n=row, replace=False, random_state=123).reset_index(drop=True)\n",
    "            num_missing = int(row * percentage)\n",
    "            missing_rows = np.random.choice(row, num_missing, replace=False)\n",
    "\n",
    "            #Selecting rows and columns to be assigned as missing\n",
    "            missing_points = []\n",
    "            for row_idx in missing_rows:\n",
    "                num_cols = np.random.randint(1, len(missing_cols) + 1)\n",
    "                cols = np.random.choice(missing_cols, size=num_cols, replace=False)\n",
    "                for col in cols:\n",
    "                    missing_points.append((row_idx, col))\n",
    "\n",
    "            # Setting the elements chosen to be missing\n",
    "            for row_idx, col in missing_points:\n",
    "                data.at[row_idx, col] = np.nan\n",
    "            \n",
    "            # Printing of missing values\n",
    "            print(f'{row}_obs_{int(percentage*100)}_percent_missing')\n",
    "            print(f\"Missing values introduced: {data.isnull().sum().sum()}\")\n",
    "            print(f\"Rows with missing values: {data.isnull().sum(axis=1).gt(0).sum()}\")\n",
    "            print(f'Number of rows {data.shape[0]}')\n",
    "            print(f'Number of cols {data.shape[1]}')\n",
    "            print(f'Number of cells {data.size}')\n",
    "            print(\"Missing values by column\")\n",
    "            print(data.isnull().sum())\n",
    "            print(\"\\n\")\n",
    "\n",
    "            #Correlation and Cramer's V of features before random fill\n",
    "            print(\"Correlation\")\n",
    "            print(data['rating'].corr(data['age']))\n",
    "            \n",
    "            for col in ['countryCode', 'generation', 'Language', 'gender', 'pilStatus']:\n",
    "                data[col] = data[col].astype('category')\n",
    "\n",
    "            results = chi_square_test(data,  ['countryCode', 'generation', 'Language', 'gender', 'pilStatus'])\n",
    "\n",
    "            for key, value in results.items():\n",
    "                print(f\"Variables: {key}, Chi2: {value[0]}, p-value: {value[1]}, Cramer's V: {value[2]:.10f}\")\n",
    "            print(\"\\n\")\n",
    "            \n",
    "            # Random fill based off dependency type\n",
    "            if name==\"low\":\n",
    "                percentage_shuffle = np.random.randint(60, 70)\n",
    "\n",
    "            elif name==\"high\":\n",
    "                percentage_shuffle = np.random.randint(10,15)\n",
    "                \n",
    "            else:\n",
    "                percentage_shuffle = np.random.randint(35, 45)\n",
    "                \n",
    "\n",
    "            data=random_fill(data,name,percentage_shuffle)\n",
    "\n",
    "            #Correlation and Cramer's V of features before random fill\n",
    "            print(\"After Random Fill\")\n",
    "            print(\"Correlation\")\n",
    "            print(data['rating'].corr(data['age']))\n",
    "     \n",
    "            results = chi_square_test(data,  ['countryCode', 'generation', 'Language', 'gender', 'pilStatus'])\n",
    "            \n",
    "            for key, value in results.items():\n",
    "                print(f\"Variables: {key}, Chi2: {value[0]}, p-value: {value[1]}, Cramer's V: {value[2]:.10f}\")\n",
    "            print(\"\\n\")\n",
    "            \n",
    "            data=data.drop(['age'],axis=1)\n",
    "\n",
    "            data.to_csv(f'{path}/{name}_{row}_obs_{int(percentage*100)}_percent_missing.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining csv paths to read\n",
    "high_dep_path=\"high_dependence.csv\"\n",
    "high_dep=pd.read_csv(high_dep_path)\n",
    "\n",
    "no_dep_path=\"low_dependence.csv\"\n",
    "no_dep=pd.read_csv(no_dep_path)\n",
    "\n",
    "moderate_dep_path=\"moderate_dependence.csv\"\n",
    "moderate_dep=pd.read_csv(moderate_dep_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining features with missings allowed, sample sizes and missing percentages of simulated data\n",
    "missing_cols=['gender','countryCode','dateOfBirth']\n",
    "obs=[10000,25000,50000]\n",
    "missing_percentages=[0,0.1,0.2]\n",
    "\n",
    "# Defining paths to save simulated datasets to\n",
    "high_dep_path=\"DataWithRelations\"\n",
    "no_dep_path=\"DataNoRelations\"\n",
    "moderate_dep_path=\"DataModerateRelations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating data with high dependency between variables\n",
    "name=\"high\"\n",
    "generating(high_dep, obs, missing_percentages, missing_cols,name,high_dep_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating data with low dependency between variables\n",
    "name=\"low\"\n",
    "generating(no_dep, obs, missing_percentages, missing_cols,name,no_dep_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating data with moderate dependency between variables\n",
    "name=\"moderate\"\n",
    "generating(moderate_dep, obs, missing_percentages, missing_cols,name,moderate_dep_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
