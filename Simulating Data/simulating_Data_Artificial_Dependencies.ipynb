{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "import random;\n",
    "from faker import Faker\n",
    "import hashlib\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake=Faker()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predefined dictionaries for simulation of data.\n",
    "\n",
    "#Generation to years\n",
    "generations_to_years = {\n",
    "    \"Silent Generation\": (1928, 1945),\n",
    "    \"Baby Boomer\": (1946, 1964),\n",
    "    \"Gen-X\": (1965, 1980),\n",
    "    \"Millennial\": (1981, 1996),\n",
    "    \"Gen-Z\": (1997, 2012),\n",
    "    \"Other\": None\n",
    "}\n",
    "\n",
    "#Ratings based off generation\n",
    "rating = {\n",
    "    'Baby Boomer': {'Female': (20, 4), 'Male': (25, 5), 'Non-Binary': (28, 6), 'None': (26, 5), 'Unknown': (18, 4)},\n",
    "    'Gen-X': {'Female': (45, 6), 'Male': (50, 5), 'Non-Binary': (55, 7), 'None': (48, 6), 'Unknown': (49, 5)},\n",
    "    'Millennial': {'Female': (70, 6), 'Male': (75, 5), 'Non-Binary': (78, 7), 'None': (73, 6), 'Unknown': (74, 5)},\n",
    "    'Gen-Z': {'Female': (80, 7), 'Male': (85, 5), 'Non-Binary': (82, 7), 'None': (83, 6), 'Unknown': (81, 6)},\n",
    "    'Silent Generation': {'Female': (22, 5), 'Male': (30, 6), 'Non-Binary': (24, 5), 'None': (28, 4), 'Unknown': (20, 3)},\n",
    "    'Other': {'Female': (65, 6), 'Male': (70, 7), 'Non-Binary': (67, 6), 'None': (68, 6), 'Unknown': (60, 5)},\n",
    "    'None': {'Female': (50, 6), 'Male': (55, 7), 'Non-Binary': (53, 6), 'None': (52, 5), 'Unknown': (51, 6)}\n",
    "}\n",
    "\n",
    "#Mapping of Country to languages. Based off most common language in country. \n",
    "country_to_languages = {\n",
    "    'AE': 'ar',\n",
    "    'AF': 'fa',\n",
    "    'AL': 'sq',\n",
    "    'AM': 'hy',\n",
    "    'AN': 'nl',\n",
    "    'AQ': 'en',\n",
    "    'AR': 'es',\n",
    "    'AS': 'sm',\n",
    "    'AT': 'de',\n",
    "    'AU': 'en',\n",
    "    'AW': 'nl',\n",
    "    'AZ': 'az',\n",
    "    'BA': 'bs',\n",
    "    'BB': 'en',\n",
    "    'BD': 'bn',\n",
    "    'BE': 'nl',\n",
    "    'BG': 'bg',\n",
    "    'BH': 'ar',\n",
    "    'BJ': 'fr',\n",
    "    'BM': 'en',\n",
    "    'BO': 'es',\n",
    "    'BR': 'pt',\n",
    "    'BT': 'dz',\n",
    "    'BY': 'be',\n",
    "    'BZ': 'en',\n",
    "    'CA': 'en',\n",
    "    'CH': 'de',\n",
    "    'CL': 'es',\n",
    "    'CN': 'zh',\n",
    "    'CO': 'es',\n",
    "    'CR': 'es',\n",
    "    'CS': 'sr',\n",
    "    'CX': 'en',\n",
    "    'CY': 'el',\n",
    "    'CZ': 'cs',\n",
    "    'DE': 'de',\n",
    "    'DK': 'da',\n",
    "    'DO': 'es',\n",
    "    'DZ': 'ar',\n",
    "    'EC': 'es',\n",
    "    'EE': 'et',\n",
    "    'EG': 'ar',\n",
    "    'ES': 'es',\n",
    "    'FI': 'fi',\n",
    "    'FM': 'en',\n",
    "    'FR': 'fr',\n",
    "    'GA': 'fr',\n",
    "    'GB': 'en',\n",
    "    'GD': 'en',\n",
    "    'GE': 'ka',\n",
    "    'GG': 'en',\n",
    "    'GH': 'en',\n",
    "    'GP': 'fr',\n",
    "    'GR': 'el',\n",
    "    'GS': 'en',\n",
    "    'GT': 'es',\n",
    "    'GU': 'en',\n",
    "    'HK': 'zh',\n",
    "    'HM': 'en',\n",
    "    'HN': 'es',\n",
    "    'HR': 'hr',\n",
    "    'HU': 'hu',\n",
    "    'ID': 'id',\n",
    "    'IE': 'en',\n",
    "    'IL': 'he',\n",
    "    'IN': 'hi',\n",
    "    'IQ': 'ar',\n",
    "    'IS': 'is',\n",
    "    'IT': 'it',\n",
    "    'JE': 'en',\n",
    "    'JM': 'en',\n",
    "    'JO': 'ar',\n",
    "    'JP': 'ja',\n",
    "    'KE': 'sw',\n",
    "    'KR': 'ko',\n",
    "    'KW': 'ar',\n",
    "    'KZ': 'ru',\n",
    "    'LB': 'ar',\n",
    "    'LK': 'si',\n",
    "    'LT': 'lt',\n",
    "    'LU': 'lb',\n",
    "    'LV': 'lv',\n",
    "    'LY': 'ar',\n",
    "    'MA': 'ar',\n",
    "    'MC': 'fr',\n",
    "    'MD': 'ro',\n",
    "    'MK': 'mk',\n",
    "    'MP': 'en',\n",
    "    'MQ': 'fr',\n",
    "    'MT': 'mt',\n",
    "    'MU': 'fr',\n",
    "    'MV': 'dv',\n",
    "    'MX': 'es',\n",
    "    'MY': 'ms',\n",
    "    'MZ': 'pt',\n",
    "    'NG': 'en',\n",
    "    'NI': 'es',\n",
    "    'NL': 'nl',\n",
    "    'NO': 'no',\n",
    "    'NR': 'en',\n",
    "    'NZ': 'en',\n",
    "    'OM': 'ar',\n",
    "    'PA': 'es',\n",
    "    'PE': 'es',\n",
    "    'PH': 'tl',\n",
    "    'PK': 'ur',\n",
    "    'PL': 'pl',\n",
    "    'PM': 'fr',\n",
    "    'PN': 'en',\n",
    "    'PR': 'es',\n",
    "    'PT': 'pt',\n",
    "    'PY': 'es',\n",
    "    'QA': 'ar',\n",
    "    'RE': 'fr',\n",
    "    'RO': 'ro',\n",
    "    'RS': 'sr',\n",
    "    'RU': 'ru',\n",
    "    'SA': 'ar',\n",
    "    'SE': 'sv',\n",
    "    'SG': 'en',\n",
    "    'SI': 'sl',\n",
    "    'SK': 'sk',\n",
    "    'SV': 'es',\n",
    "    'TG': 'fr',\n",
    "    'TH': 'th',\n",
    "    'TM': 'tk',\n",
    "    'TN': 'ar',\n",
    "    'TR': 'tr',\n",
    "    'TT': 'en',\n",
    "    'TW': 'zh',\n",
    "    'UA': 'uk',\n",
    "    'UG': 'en',\n",
    "    'UM': 'en',\n",
    "    'US': 'en',\n",
    "    'UY': 'es',\n",
    "    'VC': 'en',\n",
    "    'VE': 'es',\n",
    "    'VI': 'en',\n",
    "    'VN': 'vi',\n",
    "    'ZA': 'af',\n",
    "    'ZM': 'en',\n",
    "    'ZW': 'en',\n",
    "    None: 'en'\n",
    "}\n",
    "\n",
    "#Language to generation dictionary.\n",
    "language_to_generation = {\n",
    "    'en': 'Millennial',\n",
    "    'ar': 'Gen-X',\n",
    "    'es': 'Millennial',\n",
    "    'sm': 'Gen-Z',\n",
    "    'de': 'Millennial',\n",
    "    'sr': 'Gen-X',\n",
    "    'fr': 'Millennial',\n",
    "    'nl': 'Gen-Z',\n",
    "    'bg': 'Millennial',\n",
    "    'pt': 'Gen-X',\n",
    "    'ru': 'Millennial',\n",
    "    'zh': 'Gen-X',\n",
    "    'cs': 'Gen-Z',\n",
    "    'da': 'Millennial',\n",
    "    'et': 'Gen-X',\n",
    "    'fi': 'Millennial',\n",
    "    'sv': 'Gen-Z',\n",
    "    'el': 'Millennial',\n",
    "    'hr': 'Gen-X',\n",
    "    'hu': 'Millennial',\n",
    "    'id': 'Gen-Z',\n",
    "    'he': 'Millennial',\n",
    "    'it': 'Gen-X',\n",
    "    'ja': 'Millennial',\n",
    "    'ko': 'Gen-Z',\n",
    "    'lt': 'Millennial',\n",
    "    'mk': 'Gen-X',\n",
    "    'ms': 'Millennial',\n",
    "    'nb': 'Gen-Z',\n",
    "    'no': 'Millennial',\n",
    "    'ur': 'Gen-X',\n",
    "    'pl': 'Millennial',\n",
    "    'ro': 'Gen-Z',\n",
    "    'sk': 'Gen-X',\n",
    "    'th': 'Millennial',\n",
    "    'tr': 'Gen-X',\n",
    "    'fa': 'Millennial',\n",
    "    'ps': 'Gen-Z',\n",
    "    'sq': 'Millennial',\n",
    "    'hy': 'Gen-Z',\n",
    "    'az': 'Millennial',\n",
    "    'bs': 'Gen-Z',\n",
    "    'bn': 'Millennial',\n",
    "    'dz': 'Gen-X',\n",
    "    'ca': 'Millennial',\n",
    "    'ka': 'Gen-Z',\n",
    "    'is': 'Millennial',\n",
    "    'ta': 'Gen-X',\n",
    "    'lv': 'Millennial',\n",
    "    'mt': 'Gen-Z',\n",
    "    'dv': 'Millennial',\n",
    "    'nn': 'Gen-X',\n",
    "    'sl': 'Millennial',\n",
    "    'uk': 'Gen-Z',\n",
    "    'vi': 'Millennial',\n",
    "    'si': 'Gen-X',\n",
    "    'be': 'Millennial',\n",
    "    'ku': 'Gen-Z',\n",
    "    'tk': 'Millennial',\n",
    "    'rm': 'Gen-X',\n",
    "    'af': 'Gen-Z',\n",
    "    None: 'Gen-Z'\n",
    "}\n",
    "\n",
    "# Generation to gender dictionary\n",
    "generation_to_gender = {\n",
    "    'Millennial': 'Male',\n",
    "    'Gen-X': 'Female',\n",
    "    'Gen-Z': 'Male',\n",
    "    'Baby Boomer': 'Female',\n",
    "    'Silent Generation': 'Male',\n",
    "    None: 'Male'\n",
    "}\n",
    "\n",
    "#Gender to pilstatus\n",
    "gender_to_pilStatus = {\n",
    "    'Female': False,\n",
    "    'Male': True,\n",
    "    'Non-Binary': True,\n",
    "    None: True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for generating ratings\n",
    "def ratings_generators(row):\n",
    "    mean, std = rating.get(row['generation'], rating['None']).get(row['gender'], (60, 15))\n",
    "    return np.clip(np.random.normal(loc=mean, scale=std), 0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly filling a percentage of values in features with other values in columns based off dependency type.\n",
    "# Used to enforce different dependency types of high, moderate and low\n",
    "\n",
    "def random_fill(df,percentage,dependency):\n",
    "    data = df.copy()\n",
    "    if dependency=='high':\n",
    "          columns=['Language','gender','generation','pilStatus']\n",
    "    else:\n",
    "          columns=['Language','gender','generation','pilStatus','rating']\n",
    "    for col in columns:\n",
    "            \n",
    "            num_rows = len(data)\n",
    "            num_to_replace = int((percentage / 100) * num_rows)  \n",
    "            # Selecting indicies to replace\n",
    "            random_indices = np.random.choice(data.index, num_to_replace, replace=False)  \n",
    "            # Selecting random value to replace with\n",
    "            random_values = np.random.choice(data[col], num_to_replace, replace=True)\n",
    "            \n",
    "            data.loc[random_indices, col] = random_values\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating birth days\n",
    "def generate_birth_date(generation):\n",
    "    if generation in generations_to_years and generations_to_years[generation]:\n",
    "        start_year, end_year = generations_to_years[generation]\n",
    "        year = random.randint(start_year, end_year)\n",
    "        month = random.randint(1, 12)\n",
    "        if month == 2:\n",
    "            if year%4==0:\n",
    "                day=random.randint(1, 29)\n",
    "            else:\n",
    "                day = random.randint(1, 28)\n",
    "        elif month in [1,3,5,7,8,10,12]:\n",
    "            day = random.randint(1, 31)\n",
    "        else:\n",
    "            day=random.randint(1,30)\n",
    "        return f\"{year}-{month:02d}-{day:02d}\"\n",
    "    \n",
    "\n",
    "# Creating age feature based off birthdate\n",
    "def age_from_birthDate(birthdate):\n",
    "    today=datetime.today()\n",
    "    return today.year - birthdate.year - ((today.month, today.day) < (birthdate.month, birthdate.day))\n",
    "\n",
    "# Hasing ids\n",
    "def hash_id(value):\n",
    "    return hashlib.sha256(str(value).encode()).hexdigest()[:10]\n",
    "\n",
    "# Cramers to investigate associations between variables\n",
    "def cramers_v(df):\n",
    "    confusion_matrix = pd.crosstab(df['countryCode'],df['Language'])  \n",
    "    chi2, p, dof, expected= chi2_contingency(confusion_matrix)  \n",
    "    n = confusion_matrix.sum().sum()\n",
    "    k = min(confusion_matrix.shape)  \n",
    "    if k > 1:\n",
    "        return np.sqrt(chi2 / (n * (k - 1)))\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Function to perform Chi-Square test and calculate Cramer's V for all pairs of categorical variables\n",
    "def chi_square_test(df, cat_vars):\n",
    "    results = {}\n",
    "    for var1 in cat_vars:\n",
    "        for var2 in cat_vars:\n",
    "            if var1 != var2:\n",
    "                try:\n",
    "                    # Calculate Chi-Square and Cramer's V\n",
    "                    chi2, p, dof, ex = chi2_contingency(pd.crosstab(df[var1], df[var2]))\n",
    "                    cramer_v = cramers_v(df)\n",
    "                    results[(var1, var2)] = (chi2, p, cramer_v)\n",
    "                except ValueError:\n",
    "                    # Skip invalid pairs (e.g., if one variable has only one unique value)\n",
    "                    results[(var1, var2)] = (np.nan, np.nan, np.nan)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The csvs for counts by aggregation types used as base\n",
    "country_data=pd.read_csv(\"../Count_of_Game_Name_by_Country_Code.csv\")\n",
    "gender_data=pd.read_csv(\"../Count_of_Game_Name_by_Gender.csv\")\n",
    "language_data=pd.read_csv(\"../Count_of_Game_Name_by_Language.csv\")\n",
    "platform_data=pd.read_csv(\"../Count_of_Game_Name_by_Platform_and_Player_Generation.csv\")\n",
    "state_data=pd.read_csv(\"../Count_of_Game_Name_by_US_State.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting country data as the base dataframe that will be merged with others\n",
    "data=country_data.loc[country_data.index.repeat(country_data['COUNT'])].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing a language based off the country code\n",
    "data['Language'] = data['countryCode'].map(country_to_languages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing a generation based off the language\n",
    "data['generation'] = data['Language'].map(language_to_generation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing gender based off generation\n",
    "data['gender'] = data['generation'].map(generation_to_gender)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing pilstatus based off gender\n",
    "data['pilStatus'] = data['gender'].map(gender_to_pilStatus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting rid of the missings\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treating pilStatus as a str so I can use it to identify individuals\n",
    "data['pilStatus']=data['pilStatus'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identifying individuals\n",
    "data['ind']=data['generation']+' '+data['gender']+' '+data['countryCode']+' '+data['Language']+data['pilStatus']\n",
    "data=data.sort_values(by=['ind']).groupby(['ind'], group_keys=False).apply(lambda x: x.sample(frac=1))\n",
    "\n",
    "\n",
    "grouped = data.groupby('ind')\n",
    "result = []\n",
    "id = 1\n",
    "for name, group in grouped:\n",
    "    curr_group_length=0\n",
    "    nrow=len(group)\n",
    "    while curr_group_length<nrow:\n",
    "        # Randomly allowing a person to exist 20 - 50 times\n",
    "        repetitions = np.random.randint(20, 51)\n",
    "\n",
    "        if curr_group_length+repetitions > nrow:\n",
    "            repetitions=nrow-curr_group_length\n",
    "        # Repeat the ID repetion times\n",
    "        repeated_ids = [id] * repetitions\n",
    "\n",
    "        # Append to the result list\n",
    "        result.extend(repeated_ids)\n",
    "        curr_group_length+=repetitions\n",
    "        # Increment the ID for the next person\n",
    "        id += 1\n",
    "\n",
    "result_df = pd.DataFrame(result, columns=['id'])\n",
    "\n",
    "data = pd.concat([data.reset_index(drop=True), result_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracing only relevant features\n",
    "player=data[['id','countryCode','Language','gender','generation','pilStatus']].drop_duplicates()\n",
    "player['rating'] = player.apply(ratings_generators, axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating percentages of data to randomly fill based off dependency type\n",
    "low_percentage = np.random.randint(70, 75)\n",
    "player_low=random_fill(player.copy(),low_percentage,'low')\n",
    "\n",
    "high_percentage = np.random.randint(10,15)\n",
    "player_high=random_fill(player.copy(),high_percentage,'high')\n",
    "\n",
    "moderate_percentage = np.random.randint(35, 45)\n",
    "player_moderate=random_fill(player.copy(),moderate_percentage,'moderate')\n",
    "\n",
    "#Creating into a dictionary for easy processing\n",
    "player_data={\n",
    "      'low':player_low,\n",
    "      'moderate':player_moderate,\n",
    "      'high':player_high\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "player['hashedId']=player['id'].apply(lambda x:hash_id(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loop for creating features and measuring correlation as well as Cramer's V\n",
    "for key,player in player_data.items():\n",
    "    player['dateOfBirth']=player['generation'].apply(lambda x: generate_birth_date(x))\n",
    "    player['emailAddress']=player['id'].apply(lambda x: fake.email())\n",
    "    player['arcsId']=player['id'].apply(lambda x: fake.uuid4()[:8])\n",
    "    player['dateOfBirth']=pd.to_datetime(player['dateOfBirth'])\n",
    "    player['age']=player['dateOfBirth'].apply(age_from_birthDate)\n",
    "\n",
    "    print(key)\n",
    "    print(\"Correlation:\")\n",
    "    print(player['rating'].corr(player['age']))\n",
    "\n",
    "    for col in ['countryCode', 'generation', 'Language', 'gender', 'pilStatus']:\n",
    "        player[col] = player[col].astype('category')\n",
    "\n",
    "    results = chi_square_test(player,  ['countryCode', 'generation', 'Language', 'gender', 'pilStatus'])\n",
    "\n",
    "    # Display results\n",
    "    for key, value in results.items():\n",
    "        print(f\"Variables: {key}, Chi2: {value[0]}, p-value: {value[1]}, Cramer's V: {value[2]:.10f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving data\n",
    "for key,player in player_data.items():\n",
    "    player.to_csv(f'{key}_dependence.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
