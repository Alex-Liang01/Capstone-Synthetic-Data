{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "OnLcz0dtQj2D"
   },
   "outputs": [],
   "source": [
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "import random;\n",
    "from faker import Faker\n",
    "import hashlib\n",
    "import os\n",
    "import pathlib\n",
    "script_dir = pathlib.Path().resolve()\n",
    "os.chdir(script_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for converting counts to proportions\n",
    "def props(data,col):\n",
    "    data['props']=data.groupby(col)['COUNT'].transform(lambda x: x/sum(x))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for selecting a language based off of a country\n",
    "def selectingLanguage(country):\n",
    "        selectedCountry=country_language_prop_dict.get(country,\"\")\n",
    "        if selectedCountry==\"\":\n",
    "            return 'en'\n",
    "        else:\n",
    "            return np.random.choice(selectedCountry['languages'],p=selectedCountry['props'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining through sampling other dataframe on name\n",
    "def joining(data, otherData):\n",
    "    sampled_rows = data.groupby('name', group_keys=False).apply(\n",
    "        lambda group: otherData[otherData['name'] == group['name'].iloc[0]]\n",
    "        .sample(n=len(group), replace=True, weights='props')\n",
    "        .reset_index(drop=True)\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    sampled_rows = sampled_rows.drop(columns=['name'], errors='ignore')\n",
    "    data = data.reset_index(drop=True)\n",
    "    data = pd.concat([data, sampled_rows], axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining through sampling on states\n",
    "def joining_states(data,otherData,col):\n",
    "    data[col]=data.groupby('name', group_keys=False).apply(\n",
    "        lambda group: np.where(\n",
    "            group['countryCode'] == 'US',\n",
    "            np.random.choice(\n",
    "                otherData[otherData['name'] == group['name'].iloc[0]][col],\n",
    "                size=len(group),\n",
    "                replace=True,\n",
    "                p=otherData[otherData['name'] == group['name'].iloc[0]]['props']\n",
    "            ),np.nan)\n",
    "        ).explode().reset_index(drop=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating hashed_ids\n",
    "def hash_id(value): \n",
    "    return hashlib.sha256(str(value).encode()).hexdigest()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratings creation based off generation\n",
    "def ratings_generators(row):\n",
    "    mean, std = rating.get(row['generation'], rating['None']).get(row['gender'], (60, 15))\n",
    "    return np.clip(np.random.normal(loc=mean, scale=std), 0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulating birth dates\n",
    "def generate_birth_date(generation):\n",
    "    if generation in generations_to_years and generations_to_years[generation]:\n",
    "        start_year, end_year = generations_to_years[generation]\n",
    "        year = random.randint(start_year, end_year)\n",
    "        month = random.randint(1, 12)\n",
    "        if month == 2:\n",
    "            if year%4==0:\n",
    "                day=random.randint(1, 29)\n",
    "            else:\n",
    "                day = random.randint(1, 28)\n",
    "        elif month in [1,3,5,7,8,10,12]:\n",
    "            day = random.randint(1, 31)\n",
    "        else:\n",
    "            day=random.randint(1,30)\n",
    "        return f\"{year}-{month:02d}-{day:02d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GArgjhLzQj2K"
   },
   "outputs": [],
   "source": [
    "fake=Faker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l7i8enWxQj2L"
   },
   "outputs": [],
   "source": [
    "# Reading in counts\n",
    "country_data=pd.read_csv(\"Count_of_Game_Name_by_Country_Code.csv\")\n",
    "gender_data=pd.read_csv(\"Count_of_Game_Name_by_Gender.csv\")\n",
    "language_data=pd.read_csv(\"Count_of_Game_Name_by_Language.csv\")\n",
    "platform_data=pd.read_csv(\"Count_of_Game_Name_by_Platform_and_Player_Generation.csv\")\n",
    "state_data=pd.read_csv(\"Count_of_Game_Name_by_US_State.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xu28_QyUQj2M"
   },
   "outputs": [],
   "source": [
    "# renaming column names of platform data\n",
    "platform_data.columns=['name','platform','generation','COUNT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WBwc8OPFQj2N"
   },
   "outputs": [],
   "source": [
    "# Converting counts to proportions for each read in dataset\n",
    "\n",
    "gender_data=props(gender_data,'name')\n",
    "language_data=props(language_data,'name')\n",
    "country_data=props(country_data,'name')\n",
    "state_data=props(state_data,'name')\n",
    "platform_data=props(platform_data,'name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2KVSSvDIQj2O"
   },
   "outputs": [],
   "source": [
    "# Expanding count of rows into observations\n",
    "data=platform_data.loc[platform_data.index.repeat(platform_data['COUNT'])].reset_index(drop=True)\n",
    "country_unaggregated=country_data.loc[country_data.index.repeat(country_data['COUNT'])].reset_index(drop=True)\n",
    "state_unaggregated=state_data.loc[state_data.index.repeat(state_data['COUNT'])].reset_index(drop=True)\n",
    "language_unaggregated=language_data.loc[language_data.index.repeat(language_data['COUNT'])].reset_index(drop=True)\n",
    "platform_unaggregated=platform_data.loc[platform_data.index.repeat(platform_data['COUNT'])].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JoBg7xf9Qj2P"
   },
   "outputs": [],
   "source": [
    "# Dropping unnecessary columns\n",
    "data.drop('COUNT',axis=1,inplace=True)\n",
    "country_unaggregated.drop('COUNT',axis=1,inplace=True)\n",
    "state_unaggregated.drop('COUNT',axis=1,inplace=True)\n",
    "language_unaggregated.drop('COUNT',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M8dG_VIFQj2Q"
   },
   "outputs": [],
   "source": [
    "#Mapping of Country to languages. Based off common languages spoken in country.\n",
    "country_to_languages = {\n",
    "    'AE': ['ar'],\n",
    "    'AF': ['fa', 'ps'],\n",
    "    'AL': ['sq'],\n",
    "    'AM': ['hy'],\n",
    "    'AN': ['nl'],\n",
    "    'AQ': ['en'],\n",
    "    'AR': ['es'],\n",
    "    'AS': ['sm'],\n",
    "    'AT': ['de'],\n",
    "    'AU': ['en'],\n",
    "    'AW': ['nl'],\n",
    "    'AZ': ['az'],\n",
    "    'BA': ['bs', 'sr'],\n",
    "    'BB': ['en'],\n",
    "    'BD': ['bn'],\n",
    "    'BE': ['nl', 'fr', 'de'],\n",
    "    'BG': ['bg'],\n",
    "    'BH': ['ar'],\n",
    "    'BJ': ['fr'],\n",
    "    'BM': ['en'],\n",
    "    'BO': ['es'],\n",
    "    'BR': ['pt'],\n",
    "    'BT': ['dz'],\n",
    "    'BY': ['be', 'ru'],\n",
    "    'BZ': ['en'],\n",
    "    'CA': ['en', 'fr'],\n",
    "    'CH': ['de', 'fr', 'rm'],\n",
    "    'CL': ['es'],\n",
    "    'CN': ['zh'],\n",
    "    'CO': ['es'],\n",
    "    'CR': ['es'],\n",
    "    'CS': ['sr'],\n",
    "    'CX': ['en'],\n",
    "    'CY': ['el'],\n",
    "    'CZ': ['cs'],\n",
    "    'DE': ['de'],\n",
    "    'DK': ['da'],\n",
    "    'DO': ['es'],\n",
    "    'DZ': ['ar'],\n",
    "    'EC': ['es'],\n",
    "    'EE': ['et'],\n",
    "    'EG': ['ar'],\n",
    "    'ES': ['es', 'ca'],\n",
    "    'FI': ['fi', 'sv'],\n",
    "    'FM': ['en'],\n",
    "    'FR': ['fr'],\n",
    "    'GA': ['fr'],\n",
    "    'GB': ['en'],\n",
    "    'GD': ['en'],\n",
    "    'GE': ['ka'],\n",
    "    'GG': ['en'],\n",
    "    'GH': ['en'],\n",
    "    'GP': ['fr'],\n",
    "    'GR': ['el'],\n",
    "    'GS': ['en'],\n",
    "    'GT': ['es'],\n",
    "    'GU': ['en'],\n",
    "    'HK': ['zh', 'en'],\n",
    "    'HM': ['en'],\n",
    "    'HN': ['es'],\n",
    "    'HR': ['hr'],\n",
    "    'HU': ['hu'],\n",
    "    'ID': ['id'],\n",
    "    'IE': ['en'],\n",
    "    'IL': ['he'],\n",
    "    'IN': ['hi', 'en', 'bn', 'te', 'ta', 'ml', 'pa'],\n",
    "    'IQ': ['ar', 'ku'],\n",
    "    'IS': ['is'],\n",
    "    'IT': ['it'],\n",
    "    'JE': ['en'],\n",
    "    'JM': ['en'],\n",
    "    'JO': ['ar'],\n",
    "    'JP': ['ja'],\n",
    "    'KE': ['sw', 'en'],\n",
    "    'KR': ['ko'],\n",
    "    'KW': ['ar'],\n",
    "    'KZ': ['ru'],\n",
    "    'LB': ['ar'],\n",
    "    'LK': ['si', 'ta'],\n",
    "    'LT': ['lt'],\n",
    "    'LU': ['lb', 'fr', 'de'],\n",
    "    'LV': ['lv'],\n",
    "    'LY': ['ar'],\n",
    "    'MA': ['ar', 'fr'],\n",
    "    'MC': ['fr'],\n",
    "    'MD': ['ro'],\n",
    "    'MK': ['mk'],\n",
    "    'MP': ['en'],\n",
    "    'MQ': ['fr'],\n",
    "    'MT': ['mt'],\n",
    "    'MU': ['fr'],\n",
    "    'MV': ['dv'],\n",
    "    'MX': ['es'],\n",
    "    'MY': ['ms'],\n",
    "    'MZ': ['pt'],\n",
    "    'NG': ['en'],\n",
    "    'NI': ['es'],\n",
    "    'NL': ['nl'],\n",
    "    'NO': ['no', 'nb', 'nn'],\n",
    "    'NR': ['en'],\n",
    "    'NZ': ['en', 'mi'],\n",
    "    'OM': ['ar'],\n",
    "    'PA': ['es'],\n",
    "    'PE': ['es'],\n",
    "    'PH': ['tl', 'en'],\n",
    "    'PK': ['ur'],\n",
    "    'PL': ['pl'],\n",
    "    'PM': ['fr'],\n",
    "    'PN': ['en'],\n",
    "    'PR': ['es'],\n",
    "    'PT': ['pt'],\n",
    "    'PY': ['es'],\n",
    "    'QA': ['ar'],\n",
    "    'RE': ['fr'],\n",
    "    'RO': ['ro'],\n",
    "    'RS': ['sr'],\n",
    "    'RU': ['ru'],\n",
    "    'SA': ['ar'],\n",
    "    'SE': ['sv'],\n",
    "    'SG': ['en', 'ms', 'zh', 'ta'],\n",
    "    'SI': ['sl'],\n",
    "    'SK': ['sk'],\n",
    "    'SV': ['es'],\n",
    "    'TG': ['fr'],\n",
    "    'TH': ['th'],\n",
    "    'TM': ['tk'],\n",
    "    'TN': ['ar'],\n",
    "    'TR': ['tr'],\n",
    "    'TT': ['en'],\n",
    "    'TW': ['zh'],\n",
    "    'UA': ['uk', 'ru'],\n",
    "    'UG': ['en', 'sw'],\n",
    "    'UM': ['en'],\n",
    "    'US': ['en'],\n",
    "    'UY': ['es'],\n",
    "    'VC': ['en'],\n",
    "    'VE': ['es'],\n",
    "    'VI': ['en'],\n",
    "    'VN': ['vi'],\n",
    "    'ZA': ['af', 'en', 'zu'],\n",
    "    'ZM': ['en'],\n",
    "    'ZW': ['en']\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f3Jl8skgQj2R"
   },
   "outputs": [],
   "source": [
    "#Creating dataframe of country_to_languages dictonary\n",
    "country_to_languages=pd.DataFrame.from_dict(country_to_languages, orient='index')\n",
    "country_to_languages.columns = [f'Language_{i+1}' for i in range(country_to_languages.shape[1])]\n",
    "country_to_languages.insert(0,'Country',country_to_languages.index)\n",
    "country_to_languages.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nZTqQB-MQj2S"
   },
   "outputs": [],
   "source": [
    "#Prep for joining\n",
    "country_unaggregated.columns=['countryCode','name','country_props']\n",
    "country_language=country_unaggregated.merge(country_to_languages,how='left',left_on='countryCode',right_on='Country')\n",
    "language_unaggregated=language_unaggregated.groupby(['name','language'])['props'].first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rtxuqy3GQj2S"
   },
   "outputs": [],
   "source": [
    "#Actual joining of countries to languages based off the dictionary\n",
    "language_cols = [\"Language_1\", \"Language_2\", \"Language_3\", \"Language_4\", \"Language_5\", \"Language_6\", \"Language_7\"]\n",
    "\n",
    "for lang in language_cols:\n",
    "    country_language = country_language.merge(\n",
    "        language_unaggregated,\n",
    "        how='left',\n",
    "        left_on=['name', lang],\n",
    "        right_on=['name', 'language'],\n",
    "        suffixes=(\"\", f\"_{lang}\")\n",
    "    ).drop(columns=[\"language\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RiI938PNQj2T"
   },
   "outputs": [],
   "source": [
    "# Filling all missing props to 0 for countries that have less than 7 official languages\n",
    "columns_props = ['props', 'props_Language_2', 'props_Language_3', 'props_Language_4', 'props_Language_5', 'props_Language_6', 'props_Language_7']\n",
    "country_language[columns_props] = country_language[columns_props].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "35c6X5NrQj2T"
   },
   "outputs": [],
   "source": [
    "#Normalizing props of languages to sum up to one\n",
    "prop_cols=['props','props_Language_2','props_Language_3','props_Language_4','props_Language_5','props_Language_6','props_Language_7']\n",
    "country_language[prop_cols]=country_language[prop_cols].div(country_language[prop_cols].sum(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sYONviyOQj2T"
   },
   "outputs": [],
   "source": [
    "#Replacing missing languages with mode language of English\n",
    "country_language['Language_1']=country_language['Language_1'].fillna('en')\n",
    "country_language['props']=country_language['props'].fillna(1.0)\n",
    "country_language=country_language.rename(columns={'props':'props_Language_1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dictionary for country to languages with proportions \n",
    "country_language_dict=country_language.drop(['countryCode','name','country_props'],axis=1)\n",
    "country_language_dict=country_language_dict.drop_duplicates().reset_index(drop=True)\n",
    "country_language_prop_dict = {}\n",
    "for _, row in country_language_dict.iterrows():\n",
    "    country = row['Country']\n",
    "    languages = [row[f'Language_{i}'] for i in range(1, 8) if pd.notna(row[f'Language_{i}']) and row[f'Language_{i}'] is not None]\n",
    "    prop = [row[f'props_Language_{i}'] for i in range(1, 8) if pd.notna(row[f'Language_{i}']) and row[f'Language_{i}'] is not None]\n",
    "\n",
    "    country_language_prop_dict[country] = {\n",
    "        'languages': languages,\n",
    "        'props': prop\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating new dataframe with only necessary features\n",
    "country_language=country_language[['countryCode','name','country_props']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting language based off country code\n",
    "country_language['Language']=country_language['countryCode'].apply(selectingLanguage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "th8bSmQ8Qj2U"
   },
   "outputs": [],
   "source": [
    "#Preping country_language data to be joined with other data\n",
    "country_language.columns=['countryCode','name','props','Language']\n",
    "country_language=country_language.groupby(['countryCode','name','Language']).size().reset_index(name='COUNT').sort_values(by='name')\n",
    "country_language=props(country_language,'name')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ER21G25Qj2V"
   },
   "outputs": [],
   "source": [
    "#Joining all features together with sampling\n",
    "\n",
    "data=joining(data,gender_data)\n",
    "data=joining(data,country_language)\n",
    "data=joining_states(data,state_data,\"state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H-5PF4_XQj2V",
    "outputId": "12cac14e-a41e-4e43-f9e6-f614c84e24a5"
   },
   "outputs": [],
   "source": [
    "#Dropping of unnecessary columns\n",
    "data.drop(['props','COUNT'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_EEY9XlpQj2d"
   },
   "outputs": [],
   "source": [
    "# Creating indicators on similar individuals. Assumed that these things aren't allowed to be changed\n",
    "data.fillna(\"None\",inplace=True) \n",
    "data['ind']=data['generation']+' '+data['gender']+' '+data['countryCode']+' '+data['Language']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UFaFFdg5Qj2d"
   },
   "outputs": [],
   "source": [
    "#Shuffling of rows within indicators\n",
    "data=data.sort_values(by=['ind']).groupby(['ind','platform','state'], group_keys=False).apply(lambda x: x.sample(frac=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EKoquECGQj2d"
   },
   "outputs": [],
   "source": [
    "# Creating ids using the grouped indicators, only allowing people to exist 20-50 times within the table\n",
    "grouped = data.groupby('ind')\n",
    "result = []\n",
    "id = 1\n",
    "for name, group in grouped:\n",
    "    curr_group_length=0\n",
    "    nrow=len(group)\n",
    "    while curr_group_length<nrow:\n",
    "        # Randomly allowing a person to exist 20 - 50 times\n",
    "        repetitions = np.random.randint(20, 51)\n",
    "\n",
    "        if curr_group_length+repetitions > nrow:\n",
    "            repetitions=nrow-curr_group_length\n",
    "        # Repeat the ID repetion times\n",
    "        repeated_ids = [id] * repetitions\n",
    "\n",
    "        # Append to the result list\n",
    "        result.extend(repeated_ids)\n",
    "        curr_group_length+=repetitions\n",
    "        # Increment the ID for the next person\n",
    "        id += 1\n",
    "\n",
    "result_df = pd.DataFrame(result, columns=['id'])\n",
    "\n",
    "data = pd.concat([data.reset_index(drop=True), result_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6B_Gkp4sQj2e"
   },
   "outputs": [],
   "source": [
    "# Selecting only the relevant columns for player table\n",
    "player=data[['id','countryCode','Language','gender','generation']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nYlgovybQj2e"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Creating hashed ids\n",
    "player['hashedId']=player['id'].apply(lambda x:hash_id(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating ratings dictionary with an assumption that Gen-Z Males have the highest rating\n",
    "rating = {\n",
    "    'Baby Boomer': {'Female': (20, 4), 'Male': (25, 5), 'Non-Binary': (28, 6), 'None': (26, 5), 'Unknown': (18, 4)},\n",
    "    'Gen-X': {'Female': (45, 6), 'Male': (50, 5), 'Non-Binary': (55, 7), 'None': (48, 6), 'Unknown': (49, 5)},\n",
    "    'Millennial': {'Female': (70, 6), 'Male': (75, 5), 'Non-Binary': (78, 7), 'None': (73, 6), 'Unknown': (74, 5)},\n",
    "    'Gen-Z': {'Female': (80, 7), 'Male': (85, 5), 'Non-Binary': (82, 7), 'None': (83, 6), 'Unknown': (81, 6)},\n",
    "    'Silent Generation': {'Female': (22, 5), 'Male': (30, 6), 'Non-Binary': (24, 5), 'None': (28, 4), 'Unknown': (20, 3)},\n",
    "    'Other': {'Female': (65, 6), 'Male': (70, 7), 'Non-Binary': (67, 6), 'None': (68, 6), 'Unknown': (60, 5)},\n",
    "    'None': {'Female': (50, 6), 'Male': (55, 7), 'Non-Binary': (53, 6), 'None': (52, 5), 'Unknown': (51, 6)}\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CvbYA6FFQj2e"
   },
   "outputs": [],
   "source": [
    "# Apply function to assign ratings\n",
    "player['rating'] = player.apply(ratings_generators, axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H1UMWN45Qj2e"
   },
   "outputs": [],
   "source": [
    "# Dictionary for generations to a birth year\n",
    "generations_to_years = {\n",
    "    \"Silent Generation\": (1928, 1945),\n",
    "    \"Baby Boomer\": (1946, 1964),\n",
    "    \"Gen-X\": (1965, 1980),\n",
    "    \"Millennial\": (1981, 1996),\n",
    "    \"Gen-Z\": (1997, 2012),\n",
    "    \"Other\": None\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2_TlEjJmQj2l"
   },
   "outputs": [],
   "source": [
    "# Simulating date of births, emails, and arcsId\n",
    "player['dateOfBirth']=player['generation'].apply(lambda x: generate_birth_date(x))\n",
    "player['emailAddress']=player['id'].apply(lambda x: fake.email())\n",
    "player['arcsId']=player['id'].apply(lambda x: fake.uuid4()[:8])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0pEWpJRgQj2l"
   },
   "outputs": [],
   "source": [
    "# Only keeping relevant columns\n",
    "player=player[['id','hashedId','arcsId','countryCode','generation','dateOfBirth','emailAddress','Language','rating','gender']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JyRN7JhSQj2m"
   },
   "outputs": [],
   "source": [
    "# Simulating pilStatus\n",
    "player['pilStatus']=player['id'].apply(lambda x: random.choice([True, False])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Zzt1SL_Qj2n"
   },
   "outputs": [],
   "source": [
    "# Replacing None string back to None type for proper missing values adjustment\n",
    "player=player.replace(\"None\",None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BxhToLopQj2p"
   },
   "outputs": [],
   "source": [
    "player.to_csv(\"player.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
