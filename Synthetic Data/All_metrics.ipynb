{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0192f735",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import pandas as pd;\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pathlib\n",
    "import os\n",
    "#For random forests and Cramer's V\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# For columns shape and marginal shape scores\n",
    "from sdv.metadata import Metadata\n",
    "\n",
    "from sdv.evaluation.single_table import run_diagnostic\n",
    "from sdv.evaluation.single_table import evaluate_quality\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sdmetrics.column_pairs.statistical.contingency_similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02aed17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in simulated data for different assocciation strengths\n",
    "def readSimulatedData(folder,dependence,path):\n",
    "    rows = [10000, 25000, 50000]\n",
    "    missings = [0, 10, 20]\n",
    "    path = f\"{path}/{folder}/\"\n",
    "    dtypes = {'countryCode': 'category', 'Language': 'category', 'gender': 'category', 'pilStatus': 'category'}\n",
    "\n",
    "    #Setting up prefixes for reading data with different association strengths\n",
    "    if dependence==\"simulated\":\n",
    "        prefix=\"\"\n",
    "    elif dependence==\"high\":\n",
    "        prefix=\"high_\"\n",
    "    elif dependence==\"moderate\":\n",
    "        prefix=\"moderate_\"\n",
    "    else:\n",
    "        prefix=\"low_\"\n",
    "\n",
    "    for row in rows:\n",
    "        for missing in missings:\n",
    "            file_name = f\"{prefix}{row}_obs_{missing}_percent_missing.csv\"\n",
    "            name=f\"data_{row}_{missing}\"\n",
    "            globals()[name]= pd.read_csv(path + file_name, dtype=dtypes)\n",
    "            \n",
    "    return dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b747c447",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in synthetic data for different assocciation strengths\n",
    "def readSyntheticData(dependence,folder_path):\n",
    "    rows = [10000,25000, 50000]\n",
    "    missings = [0, 10, 20]\n",
    "    synthetic_types=['GC','CTGAN','TVAE']\n",
    "    dtypes = {'countryCode': 'category', 'Language': 'category', 'gender': 'category', 'pilStatus': 'category'}\n",
    "\n",
    "    # Setting up paths for different association strengths\n",
    "    if dependence==\"Synthetic Data\":\n",
    "        path = f\"{folder_path}/{dependence}/Synthetic Datasets/\"\n",
    "    elif dependence==\"high\":\n",
    "        path = f\"{folder_path}/Simulating Data/Dependency/Dependency Synthetic Data/High/\"\n",
    "    elif dependence==\"moderate\":\n",
    "         path = f\"{folder_path}/Simulating Data/Dependency/Dependency Synthetic Data/Moderate/\"\n",
    "    else:\n",
    "        path = f\"{folder_path}/Simulating Data/Dependency/Dependency Synthetic Data/Low/\"\n",
    "      \n",
    "    # For loop for reading in synthetic data from different paths\n",
    "    for row in rows:\n",
    "        for missing in missings:\n",
    "                for synthetic_type in synthetic_types:\n",
    "                    file_synthetic_type=str.lower(synthetic_type) \n",
    "                    file_name = f\"{row} rows_synthetic_{file_synthetic_type}.csv\"\n",
    "                    name=f\"{synthetic_type}_data_{row}_{missing}\"\n",
    "                    print(name)\n",
    "                    folder_name=f\"{row} row {missing} missing/{synthetic_type}/\"\n",
    "                    globals()[name]= pd.read_csv(path + folder_name + file_name,dtype=dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203078dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating lists for 0%, 10%, 20% missing data simulated datasets\n",
    "def simulated_lists(rows,missings):\n",
    "    for row in rows:\n",
    "        name=f\"data_{row}\"\n",
    "        globals()[name]=[]\n",
    "        for missing in missings:\n",
    "            variable=f'data_{row}_{missing}'\n",
    "            globals()[name].append(globals()[variable])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511d2c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of synthetic data sets\n",
    "def synthesizer_lists(synthesizers,rows,missings):\n",
    "    for synthesizer in synthesizers:\n",
    "        for row in rows:\n",
    "            name=f\"{synthesizer}_{row}_data\"\n",
    "            globals()[name]=[]\n",
    "            for missing in missings:\n",
    "                variable=f'{synthesizer}_data_{row}_{missing}'\n",
    "                globals()[name].append(globals()[variable])\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59278263",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging the lists of data frames for each synthesizer/simulated data type. All synthesizer dataframes in one list\n",
    "def mergeList(list1,list2,list3):\n",
    "    merged_list = list1+list2+list3\n",
    "    return merged_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9ea391",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating meta data for column shape scores\n",
    "def createMetadata(df_list):\n",
    "    metadata_list=[]\n",
    "    for df in df_list:\n",
    "        #Auto detection of datatypes for features\n",
    "        metadata = Metadata.detect_from_dataframe(data=df)\n",
    "\n",
    "        #Manual enforcing of datatypes for features\n",
    "        metadata.update_column(column_name=\"arcsId\", sdtype=\"id\")\n",
    "        metadata.update_column(column_name=\"hashedId\", sdtype=\"id\")\n",
    "        metadata.update_column(column_name=\"countryCode\",sdtype=\"categorical\")\n",
    "        metadata.update_column(column_name=\"Language\",sdtype=\"categorical\")\n",
    "        metadata_list.append(metadata)\n",
    "        \n",
    "    return metadata_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e69120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating age feature for random forests and correlation\n",
    "def age(df):\n",
    "    today=datetime.today()\n",
    "    df['dateOfBirth']=pd.to_datetime(df['dateOfBirth'])\n",
    "    df['age']=df['dateOfBirth'].apply(lambda x: today.year - x.year - ((today.month, today.day) < (x.month, x.day)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba30814",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing to categorical\n",
    "def preprocessing(df_list):\n",
    "    categorical_cols=['countryCode','gender','pilStatus','Language']\n",
    "    for df in df_list:\n",
    "        df.dropna(axis=0,inplace=True)\n",
    "        df[categorical_cols]=df[categorical_cols].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b56770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between age and rating\n",
    "def correlation(data):\n",
    "    return data['rating'].corr(data['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11485707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating custom Cramer's V calculation\n",
    "def cramers_v(df):\n",
    "    confusion_matrix = pd.crosstab(df['countryCode'],df['Language'])  \n",
    "    chi2, p, dof, expected= chi2_contingency(confusion_matrix)  \n",
    "    n = confusion_matrix.sum().sum()\n",
    "    k = min(confusion_matrix.shape)  \n",
    "    if k > 1:\n",
    "        return np.sqrt(chi2 / (n * (k - 1)))\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d64737",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random forest predicting ratings with gender, age, language, countryCode, Language. Returns MAE.\n",
    "\n",
    "def rf(data):\n",
    "    X = data.drop(['rating', 'id', 'hashedId', 'arcsId', 'dateOfBirth', 'emailAddress', 'generation'], axis=1, errors='ignore')\n",
    "    y = data['rating']\n",
    "\n",
    "    numeric_cols = X.select_dtypes(include=['number']).columns\n",
    "    categorical_cols = X.select_dtypes(include=['category','object']).columns\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X[numeric_cols] = scaler.fit_transform(X[numeric_cols])\n",
    "\n",
    "    model = lgb.LGBMRegressor(\n",
    "        boosting_type='rf',\n",
    "        n_estimators=300,\n",
    "        max_depth=15,\n",
    "        subsample=0.8,\n",
    "        subsample_freq=1,\n",
    "        colsample_bytree=0.8,\n",
    "        min_child_samples=5,\n",
    "        device='cpu',\n",
    "        random_state=123,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    cv_scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "\n",
    "    return -cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f30ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating reports for marginal shape scores and column shape scores\n",
    "def make_report(sim,syn,meta):\n",
    "    diagnostic = run_diagnostic(\n",
    "    real_data=sim,\n",
    "    synthetic_data=syn,\n",
    "    metadata=meta\n",
    "    )\n",
    "    quality_report = evaluate_quality(\n",
    "    real_data=sim,\n",
    "    synthetic_data=syn,\n",
    "    metadata=meta\n",
    "    )\n",
    "    return (diagnostic,quality_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd17ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop for getting column shape and marginal shape scores for all datasets\n",
    "def report_loop(sim,syn,meta):\n",
    "    report_list=[]\n",
    "    for i,df in enumerate(sim):\n",
    "        report=make_report(sim[i],syn[i],meta[i])\n",
    "        report_list.append(report)\n",
    "    return report_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6401ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting column shape scores\n",
    "def get_column_metrics(report_list,Synthesizer_type,df_type):\n",
    "    df = [] \n",
    "    for i,item in enumerate(report_list):   \n",
    "        columns_scores= item[1].get_properties()\n",
    "        columns_scores['df_type']=df_type[i]\n",
    "        df.append(columns_scores)\n",
    "    df=pd.concat(df, axis=0, ignore_index=True)\n",
    "\n",
    "    df['synthesizer_type']=Synthesizer_type\n",
    "  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e912ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting marginal shape scores\n",
    "\n",
    "def get_marginal_metrics(report_list,Synthesizer_type,df_type):\n",
    "\n",
    "    df = [] \n",
    "    for i,item in enumerate(report_list):   \n",
    "        columns_scores= item[1].get_details('Column Shapes')\n",
    "        columns_scores['df_type']=df_type[i]\n",
    "        df.append(columns_scores)\n",
    "    df=pd.concat(df, axis=0, ignore_index=True)\n",
    "\n",
    "    df['synthesizer_type']=Synthesizer_type\n",
    "  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9435f9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating age feature\n",
    "def preprocessing_age(df_list):\n",
    "    categorical_cols=['countryCode','gender','pilStatus','Language']\n",
    "    for df in df_list:\n",
    "        age(df)\n",
    "        df.dropna(axis=0,inplace=True)\n",
    "        df[categorical_cols]=df[categorical_cols].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c2deb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop for getting correlation out of all datasets\n",
    "def correlationLoop(simulatedList,gcList,ctganList,tvaeList,row_names):\n",
    "\n",
    "    col_names = [\n",
    "        \"Simulated\", \"GC\", \"CTGAN\", \"TVAE\" \n",
    "    ]\n",
    "    corr= pd.DataFrame(index=row_names, columns=col_names)\n",
    "    for i, row_name in enumerate(row_names):\n",
    "        corr.at[row_names[i], \"Simulated\"] = correlation(simulatedList[i])\n",
    "        corr.at[row_names[i], \"GC\"] = correlation(gcList[i])\n",
    "        corr.at[row_names[i], \"CTGAN\"] = correlation(ctganList[i])\n",
    "        corr.at[row_names[i], \"TVAE\"] =correlation(tvaeList[i])\n",
    "        \n",
    "    return corr     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c29b748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop for getting Cramer's V out of all datasets\n",
    "def cramersLoop(simulatedList,gcList,ctganList,tvaeList,row_names):\n",
    "\n",
    "    col_names = [\n",
    "        \"Simulated\", \"GC\", \"CTGAN\", \"TVAE\" \n",
    "    ]\n",
    "    cramer= pd.DataFrame(index=row_names, columns=col_names)\n",
    "    for i, row_name in enumerate(row_names):\n",
    "        cramer.at[row_names[i], \"Simulated\"] = cramers_v(simulatedList[i])\n",
    "        cramer.at[row_names[i], \"GC\"] = cramers_v(gcList[i])\n",
    "        cramer.at[row_names[i], \"CTGAN\"] = cramers_v(ctganList[i])\n",
    "        cramer.at[row_names[i], \"TVAE\"] =cramers_v(tvaeList[i])\n",
    "        \n",
    "    return cramer     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e711eb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest loop on every dataset\n",
    "def rfLoop(simulatedList,gcList,ctganList,tvaeList,row_names):\n",
    "    col_names = [\n",
    "        \"Simulated\", \"GC\", \"CTGAN\", \"TVAE\" \n",
    "    ]\n",
    "    mae= pd.DataFrame(index=row_names, columns=col_names)\n",
    "    for i, row_name in enumerate(row_names):\n",
    "        mae.at[row_names[i], \"Simulated\"] = rf(simulatedList[i])\n",
    "        mae.at[row_names[i], \"GC\"] = rf(gcList[i])\n",
    "        mae.at[row_names[i], \"CTGAN\"] = rf(ctganList[i])\n",
    "        mae.at[row_names[i], \"TVAE\"] =rf(tvaeList[i])\n",
    "        \n",
    "    return mae     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b41d419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving metrics to specified path\n",
    "def saveMetrics(dependence,marginalScores,columnScores,cramers,corr,mae,simulated_cramers,simulated_corr,simulated_mae):\n",
    "    # Setting path based of dependency type\n",
    "    if dependence==\"simulated\":\n",
    "        prefix_path=\"\"\n",
    "    elif dependence==\"high\":\n",
    "        prefix_path=f'{parent_dir}/Simulating Data/Dependency/Dependency Synthetic Data/High/'\n",
    "    elif dependence==\"moderate\":\n",
    "        prefix_path=f'{parent_dir}/Simulating Data/Dependency/Dependency Synthetic Data/Moderate/'\n",
    "    else:\n",
    "        prefix_path=f'{parent_dir}/Simulating Data/Dependency/Dependency Synthetic Data/Low/'\n",
    "\n",
    "    #Saving metrics\n",
    "    marginalScores.to_csv(f'{prefix_path}marginalScores1.csv',index=False)\n",
    "    columnScores.to_csv(f'{prefix_path}columnScores1.csv',index=False)\n",
    "        \n",
    "    cramers.to_csv(f'{prefix_path}cramers1.csv')\n",
    "    corr.to_csv(f'{prefix_path}corr1.csv')\n",
    "    mae.to_csv(f'{prefix_path}mae1.csv')\n",
    "\n",
    "    simulated_cramers.to_csv(f'{prefix_path}simulated_cramers1.csv')\n",
    "    simulated_corr.to_csv(f'{prefix_path}simulated_corr1.csv')\n",
    "    simulated_mae.to_csv(f'{prefix_path}simulated_mae1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc0da06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main function for each association strength type\n",
    "def main(simulatedDataPath,dependency,syntheticDataDependency):\n",
    "    #Lists used in functions\n",
    "    rows = [10000, 25000, 50000]\n",
    "    missings = [0, 10, 20]\n",
    "    df_type = ['10000 row 0 missing','10000 row 10 missing','10000 row 20 missing',\n",
    "             '25000 row 0 missing','25000 row 10 missing','25000 row 20 missing',\n",
    "             '50000 row 0 missing','50000 row 10 missing','50000 row 20 missing']\n",
    "    \n",
    "    \n",
    "    row_names = [\"10000 rows - 0% Missing\", \"10000 rows - 10% Missing\", \"10000 rows - 20% Missing\",\n",
    "                \"25000 rows - 0% Missing\", \"25000 rows - 10% Missing\", \"25000 rows - 20% Missing\",\n",
    "                \"50000 rows - 0% Missing\", \"50000 rows - 10% Missing\", \"50000 rows - 20% Missing\"]\n",
    "    \n",
    "    #Reading in simulated data and synthetic data\n",
    "    dependence=readSimulatedData(simulatedDataPath,dependency,parent_dir)\n",
    "    readSyntheticData(syntheticDataDependency,parent_dir)\n",
    "    \n",
    "    #Creating lists for synthetic and simulated data\n",
    "    simulated_lists([\"10000\",\"25000\",\"50000\"],[\"0\",\"10\",\"20\"])\n",
    "    synthesizer_lists([\"GC\",\"CTGAN\",\"TVAE\"],[\"10000\",\"25000\",\"50000\"],[\"0\",\"10\",\"20\"])\n",
    "\n",
    "    Simulated_data=mergeList(data_10000, data_25000, data_50000)\n",
    "    GC_data=mergeList(GC_10000_data,GC_25000_data,GC_50000_data)\n",
    "    CTGAN_data=mergeList(CTGAN_10000_data,CTGAN_25000_data,CTGAN_50000_data)\n",
    "    TVAE_data=mergeList(TVAE_10000_data,TVAE_25000_data,TVAE_50000_data)\n",
    "\n",
    "    #Creating metadata for column shape and marginal shape scores\n",
    "    metadata=createMetadata(Simulated_data)\n",
    "    \n",
    "    #Preprocessing data to categorical\n",
    "    preprocessing(Simulated_data)\n",
    "    preprocessing(GC_data)\n",
    "    preprocessing(CTGAN_data)\n",
    "    preprocessing(TVAE_data)\n",
    "    \n",
    "    all_dataset={\n",
    "        'Simulated':Simulated_data,\n",
    "        'GC':GC_data,\n",
    "        'CTGAN':CTGAN_data,\n",
    "        'TVAE':TVAE_data,\n",
    "        'Metadata':metadata,\n",
    "    }\n",
    "\n",
    "    #Running column score and marginal score methods\n",
    "    gc_report_list=report_loop(all_dataset['Simulated'],all_dataset['GC'],all_dataset['Metadata'])\n",
    "    ctgan_report_list=report_loop(all_dataset['Simulated'],all_dataset['CTGAN'],all_dataset['Metadata'])\n",
    "    tvae_report_list=report_loop(all_dataset['Simulated'],all_dataset['TVAE'],all_dataset['Metadata'])\n",
    "\n",
    "    #Extracting column metrics\n",
    "    gc_columnsScores=get_column_metrics(gc_report_list,\"GC\",df_type)\n",
    "    ctgan_columnsScores=get_column_metrics(ctgan_report_list,\"CTGAN\",df_type)\n",
    "    tvae_columnsScores=get_column_metrics(tvae_report_list,\"TVAE\",df_type)\n",
    "    columnScores=pd.concat([gc_columnsScores,ctgan_columnsScores,tvae_columnsScores],axis=0,ignore_index=True)\n",
    "\n",
    "    #Extracting marginal distribution metrics\n",
    "    gc_marginalScores=get_marginal_metrics(gc_report_list,\"GC\",df_type)\n",
    "    ctgan_marginalScores=get_marginal_metrics(ctgan_report_list,\"CTGAN\",df_type)\n",
    "    tvae_marginalScores=get_marginal_metrics(tvae_report_list,\"TVAE\",df_type)\n",
    "    marginalScores=pd.concat([gc_marginalScores,ctgan_marginalScores,tvae_marginalScores],axis=0,ignore_index=True)\n",
    "\n",
    "    #Preproceessing age feature\n",
    "    preprocessing_age(Simulated_data) \n",
    "    preprocessing_age(GC_data)\n",
    "    preprocessing_age(CTGAN_data)\n",
    "    preprocessing_age(TVAE_data)\n",
    "\n",
    "    # Running loops for correlation, cramer's v and random forests\n",
    "    corr=correlationLoop(Simulated_data,GC_data,CTGAN_data,TVAE_data,row_names)\n",
    "    cramers=cramersLoop(Simulated_data,GC_data,CTGAN_data,TVAE_data,row_names)\n",
    "    mae=rfLoop(Simulated_data,GC_data,CTGAN_data,TVAE_data,row_names)\n",
    "\n",
    "    #Extracting results for the simulated dataset\n",
    "    simulated_corr=corr[['Simulated']]\n",
    "    simulated_cramers=cramers[['Simulated']]\n",
    "    simulated_mae=mae[['Simulated']]\n",
    "    \n",
    "    #Saving results\n",
    "    saveMetrics(dependence,marginalScores,columnScores,cramers,corr,mae,simulated_cramers,simulated_corr,simulated_mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90c6f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_dir = pathlib.Path().resolve()\n",
    "os.chdir(script_dir)\n",
    "parent_dir=script_dir.parent\n",
    "\n",
    "#Running main with different association strengths\n",
    "main(\"Simulated Data\",\"simulated\",\"Synthetic Data\")\n",
    "main(\"Simulating Data/Dependency/DataWithRelations\",\"high\",\"high\")\n",
    "main(\"Simulating Data/Dependency/DataModerateRelations\",\"moderate\",\"moderate\")\n",
    "main(\"Simulating Data/Dependency/DataNoRelations\",\"low\",\"low\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
