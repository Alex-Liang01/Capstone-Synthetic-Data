{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55496b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96f54638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in data of different metrics based off dependency type with different paths for different association strengths\n",
    "def readData(dependency):\n",
    "    # Setting paths for different dependency strengths\n",
    "    if dependency==\"simulated\":\n",
    "        multiple_iters_path=''\n",
    "        simulated_path='../'\n",
    "    \n",
    "    elif dependency==\"high\":\n",
    "        multiple_iters_path='../../Simulating Data/Dependency/Synthetic Data Multiple Iterations/High/'\n",
    "        simulated_path='../../Simulating Data/Dependency/Dependency Synthetic Data/High/'\n",
    "\n",
    "    elif dependency==\"moderate\":\n",
    "        multiple_iters_path='../../Simulating Data/Dependency/Synthetic Data Multiple Iterations/Moderate/'\n",
    "        simulated_path='../../Simulating Data/Dependency/Dependency Synthetic Data/Moderate/'\n",
    "\n",
    "    else:\n",
    "        multiple_iters_path='../../Simulating Data/Dependency/Synthetic Data Multiple Iterations/Low/'\n",
    "        simulated_path='../../Simulating Data/Dependency/Dependency Synthetic Data/Low/'\n",
    "\n",
    "    # Reading in csvs for multiple synthetic datasets' Cramers, MAE, and correlation values\n",
    "    cramers_df=pd.read_csv(f'{multiple_iters_path}cramers_multiple_iters.csv')\n",
    "    mae_df=pd.read_csv(f'{multiple_iters_path}mae_multiple_iters.csv')\n",
    "    corr_df=pd.read_csv(f'{multiple_iters_path}corr_multiple_iters.csv')\n",
    "\n",
    "    # Reading in csvs for simulated dataset's Cramers, MAE, and correlation values\n",
    "    cramers_simulated=pd.read_csv(f'{simulated_path}/simulated_cramers.csv')\n",
    "    mae_simulated=pd.read_csv(f'{simulated_path}/simulated_MAE.csv')\n",
    "    corr_simulated=pd.read_csv(f'{simulated_path}/simulated_corr.csv')\n",
    "    \n",
    "    return cramers_df,mae_df,corr_df,cramers_simulated,mae_simulated,corr_simulated,corr_simulated,dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6ce055d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving metrics for visualization in Tableau\n",
    "def save_metrics(dependency,cramers,mae,corr):\n",
    "\n",
    "    # Setting save path based off dependency type\n",
    "    if dependency==\"simulated\":\n",
    "        save_path=''\n",
    "\n",
    "    elif dependency==\"high\":\n",
    "        save_path='../../Simulating Data/Dependency/Synthetic Data Multiple Iterations/High/'\n",
    "\n",
    "    elif dependency==\"moderate\":\n",
    "        save_path='../../Simulating Data/Dependency/Synthetic Data Multiple Iterations/Moderate/'\n",
    "\n",
    "    else:\n",
    "        save_path='../../Simulating Data/Dependency/Synthetic Data Multiple Iterations/Low/'\n",
    "\n",
    "    # Saving joined metrics to defined path\n",
    "    cramers.to_csv(f'{save_path}cramers_joined1.csv',index=False)\n",
    "    mae.to_csv(f'{save_path}mae_joined1.csv',index=False)\n",
    "    corr.to_csv(f'{save_path}corr_joined1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4adda668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function for merging files based off different association strengthsd\n",
    "def main(dependence):\n",
    "\n",
    "    #Reading data\n",
    "    cramers_df,mae_df,corr_df,cramers_simulated,mae_simulated,corr_simulated,corr_simulated,dependency=readData(dependence)\n",
    "\n",
    "    # Melting metrics from multiple synthetic datasets\n",
    "    cramers=pd.melt(cramers_df)\n",
    "    mae=pd.melt(mae_df)\n",
    "    corr=pd.melt(corr_df)\n",
    "    \n",
    "    #Renaming columns\n",
    "    cramers_simulated.columns=['variable','Simulated']\n",
    "    mae_simulated.columns=['variable','Simulated']\n",
    "    corr_simulated.columns=['variable','Simulated']\n",
    "\n",
    "    # Getting row and missing from variable feature\n",
    "    split=corr_simulated['variable'].str.split('-')\n",
    "    rows = []\n",
    "    missings = []\n",
    "    for elem in split:\n",
    "        row=re.findall(r'\\d+',elem[0])\n",
    "        missing=re.findall(r'\\d+',elem[1])\n",
    "        rows.append(row)\n",
    "        missings.append(missing)\n",
    "\n",
    "    # Creating a dataframe with rows and missing string columns    \n",
    "    data=pd.DataFrame({\n",
    "        'Row': rows,\n",
    "        'Missing': missings\n",
    "    })\n",
    "    data['Row']=data['Row'].explode()\n",
    "    data['Missing']=data['Missing'].explode()\n",
    "    data['Variable']=data['Row']+'_'+data['Missing']\n",
    "    data.drop(['Row','Missing'],inplace=True,axis=1)\n",
    "    \n",
    "    # Adding row and missing columns to simulated data\n",
    "    cramers_simulated=pd.concat([data,cramers_simulated],axis=1)\n",
    "    cramers_simulated.drop('variable',axis=1,inplace=True)\n",
    "\n",
    "    mae_simulated=pd.concat([data,mae_simulated],axis=1)\n",
    "    mae_simulated.drop('variable',axis=1,inplace=True)\n",
    "\n",
    "    corr_simulated=pd.concat([data,corr_simulated],axis=1)\n",
    "    corr_simulated.drop('variable',axis=1,inplace=True)\n",
    "\n",
    "    # Extracting synthesizer type as it's own column\n",
    "    cramers['type']=cramers['variable'].apply(lambda x: '_'.join(x.split('_')[1:]))\n",
    "    mae['type']=mae['variable'].apply(lambda x: '_'.join(x.split('_')[1:]))\n",
    "    corr['type']=corr['variable'].apply(lambda x: '_'.join(x.split('_')[1:]))\n",
    "    \n",
    "    # Merging based on variable name and extracting only relevant columns\n",
    "    cramers=cramers.merge(cramers_simulated,how='inner',left_on='type',right_on='Variable')\n",
    "    cramers=cramers[['variable','value','Simulated']]\n",
    "\n",
    "    mae=mae.merge(mae_simulated,how='inner',left_on='type',right_on='Variable')\n",
    "    mae=mae[['variable','value','Simulated']]\n",
    "\n",
    "    corr=corr.merge(corr_simulated,how='inner',left_on='type',right_on='Variable')\n",
    "    corr=corr[['variable','value','Simulated']]\n",
    "\n",
    "    save_metrics(dependency,cramers,mae,corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4d1139",
   "metadata": {},
   "outputs": [],
   "source": [
    "main(\"simulated\")\n",
    "main(\"high\")\n",
    "main(\"moderate\")\n",
    "main(\"low\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
