{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "executionInfo": {
     "elapsed": 309,
     "status": "error",
     "timestamp": 1742333486632,
     "user": {
      "displayName": "Chelsy Nguyen",
      "userId": "12641738153105832899"
     },
     "user_tz": 420
    },
    "id": "XGW9aBPwGTC0",
    "outputId": "bd222117-f454-4aa3-fe6c-ffbe789694c8"
   },
   "outputs": [],
   "source": [
    "## Importing libaries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "## For synthesize\n",
    "from sdv.metadata import Metadata\n",
    "from sdv.single_table import GaussianCopulaSynthesizer, CTGANSynthesizer, TVAESynthesizer\n",
    "from sdv.datasets.local import load_csvs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24806,
     "status": "ok",
     "timestamp": 1742164831152,
     "user": {
      "displayName": "Chelsy Nguyen",
      "userId": "12641738153105832899"
     },
     "user_tz": 420
    },
    "id": "6JHRd-_mATBz",
    "outputId": "4ffaba43-5217-4837-f8d2-c7c0e887339e"
   },
   "outputs": [],
   "source": [
    "## Load data\n",
    "def read_Data(dependency):\n",
    "    if dependency==\"simulated\":\n",
    "        prefix=\"\"\n",
    "        all_files = load_csvs(f'{parent_dir}/Simulated Data/')\n",
    "    elif dependency==\"high\":\n",
    "        prefix=\"high_\"\n",
    "        all_files = load_csvs(f'{parent_dir}/Simulating Data/Dependency/DataWithRelations/')\n",
    "    elif dependency==\"moderate\":\n",
    "        prefix=\"moderate_\"\n",
    "        all_files = load_csvs(f'{parent_dir}/Simulating Data/Dependency/DataModerateRelations/')\n",
    "    else:\n",
    "        prefix=\"low_\"\n",
    "        all_files = load_csvs(f'{parent_dir}/Simulating Data/Dependency/DataNoRelations/')\n",
    "\n",
    "    df_10000_0 = all_files[f'{prefix}10000_obs_0_percent_missing']\n",
    "    df_10000_10 = all_files[f'{prefix}10000_obs_10_percent_missing']\n",
    "    df_10000_20 = all_files[f'{prefix}10000_obs_20_percent_missing']\n",
    "    df_25000_0 = all_files[f'{prefix}25000_obs_0_percent_missing']\n",
    "    df_25000_10 = all_files[f'{prefix}25000_obs_10_percent_missing']\n",
    "    df_25000_20 = all_files[f'{prefix}25000_obs_20_percent_missing']\n",
    "    df_50000_0 = all_files[f'{prefix}50000_obs_0_percent_missing']\n",
    "    df_50000_10 = all_files[f'{prefix}50000_obs_10_percent_missing']\n",
    "    df_50000_20 = all_files[f'{prefix}50000_obs_20_percent_missing']    \n",
    "\n",
    "    all_df = list([df_10000_0, df_10000_10, df_10000_20,\n",
    "               df_25000_0, df_25000_10, df_25000_20,\n",
    "              df_50000_0, df_50000_10, df_50000_20\n",
    "               ])\n",
    "        \n",
    "    return all_df,dependency         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Sebzzlhb9qk"
   },
   "outputs": [],
   "source": [
    "#-----------------------------------------------------\n",
    "## Function synthesize_data: Takes in a dataframe, number of rows to synthesize, output folder path index, \n",
    "## and dependency of dependency for saving data \n",
    "\n",
    "def synthesize_data(df, n, index,dependency):\n",
    "  #Creating metadata for synthesizing datasets\n",
    "  metadata = Metadata.detect_from_dataframe(data=df)\n",
    "\n",
    "  metadata.update_column(column_name=\"arcsId\", sdtype=\"id\")\n",
    "  metadata.update_column(column_name=\"hashedId\", sdtype=\"id\")\n",
    "  metadata.update_column(column_name=\"countryCode\",sdtype=\"categorical\")\n",
    "  metadata.update_column(column_name=\"Language\",sdtype=\"categorical\")\n",
    "\n",
    "  ## Train synthesizers\n",
    "\n",
    "  #GC\n",
    "  gc_syn = GaussianCopulaSynthesizer(metadata)\n",
    "  gc_syn.fit(df)\n",
    "  #CTGAN\n",
    "  ctgan_syn = CTGANSynthesizer(metadata,cuda=True)\n",
    "  ctgan_syn.fit(df)\n",
    "  #TVAE\n",
    "  tvae_syn = TVAESynthesizer(metadata,cuda=True)\n",
    "  tvae_syn.fit(df)\n",
    "  print(f\"Training synthesizers completed!\")\n",
    "\n",
    "  ## Creating paths for saving synthetic datasets\n",
    "  if dependency==\"simulated\":\n",
    "    output_path= f'{script_dir}/Synthetic Datasets/' + str(index) + '/' \n",
    "\n",
    "  elif dependency==\"high\":\n",
    "    output_path= f'{parent_dir}/Simulating Data/Dependency/Dependency Synthetic Data/High/' + str(index) + '/' \n",
    "\n",
    "  elif dependency==\"moderate\":\n",
    "    output_path= f'{parent_dir}/Simulating Data/Dependency/Dependency Synthetic Data/Moderate/' + str(index) + '/' \n",
    " \n",
    "  else:\n",
    "    output_path= f'{parent_dir}/Simulating Data/Dependency/Dependency Synthetic Data/Low/' + str(index) + '/' \n",
    "\n",
    "  ## Create synthetic data\n",
    "  gc_df = gc_syn.sample(num_rows=n)\n",
    "  ctgan_df = ctgan_syn.sample(num_rows=n)\n",
    "  tvae_df = tvae_syn.sample(num_rows=n)\n",
    "  print(f\"Data generation completed!\")\n",
    "\n",
    "  ## Export the data to a CSV file\n",
    "\n",
    "  ## Making specific directories\n",
    "  out_gc = output_path + \"GC/\"\n",
    "  out_ctgan = output_path + \"CTGAN/\"\n",
    "  out_tvae = output_path + \"TVAE/\"\n",
    "  os.makedirs(out_gc, exist_ok=True)\n",
    "  os.makedirs(out_ctgan, exist_ok=True)\n",
    "  os.makedirs(out_tvae, exist_ok=True)\n",
    "  \n",
    "  ## Export\n",
    "  gc_df.to_csv(out_gc + str(n) + f' rows_synthetic_gc.csv', index=False)\n",
    "  ctgan_df.to_csv(out_ctgan + str(n) + f' rows_synthetic_ctgan.csv', index=False)\n",
    "  tvae_df.to_csv(out_tvae + str(n) + f' rows_synthetic_tvae.csv', index=False)\n",
    "  print(f\"Data exported completed!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full pipeline from reading to synthesizing and saving synthetic datasets\n",
    "def fullPipeline(dependency):\n",
    "    #Reading simulated data\n",
    "    all_df,dependency=read_Data(dependency)\n",
    "\n",
    "    # Process datetime for synthesizers\n",
    "    for df in all_df:\n",
    "        df['dateOfBirth'] = pd.to_datetime(df['dateOfBirth'], errors='coerce')\n",
    "    \n",
    "    # Lists for synthetic data sample sizes\n",
    "    all_rows = list([10000,10000,10000, 25000,25000,25000, 50000,50000,50000])\n",
    "    df_type = ['10000 row 0 missing','10000 row 10 missing','10000 row 20 missing',\n",
    "                '25000 row 0 missing','25000 row 10 missing','25000 row 20 missing',\n",
    "                '50000 row 0 missing','50000 row 10 missing','50000 row 20 missing']\n",
    "\n",
    "    #Generating synthetic data\n",
    "    print(f'Generating synthetic data for {dependency} data')\n",
    "    for i in range(9): \n",
    "        print(\"-----------Generating dataframe \" + df_type[i] + ' ----------------')\n",
    "        synthesize_data(all_df[i], all_rows[i], df_type[i],dependency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up paths\n",
    "script_dir = pathlib.Path().resolve()\n",
    "os.chdir(script_dir)\n",
    "parent_dir=script_dir.parent\n",
    "\n",
    "# Full pipelines for synthesizing data\n",
    "fullPipeline(\"simulated\")\n",
    "fullPipeline(\"high\")\n",
    "fullPipeline(\"moderate\")\n",
    "fullPipeline(\"low\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
